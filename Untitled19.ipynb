{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6bIa2tR99A6UiLdi+PaTV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LAVANYAVARANASI-123/Google-Cloud-Jam-Module-7/blob/main/Untitled19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsNOL47_CsdL"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "#re - regular expression which helps for pattern matching"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'''if you want to match any digits like a phone number we can check our re by going to \"regex101.com\" and using respective symbol displayed at explanation\n",
        "for matching a single digit we use /d\n",
        "for 2 digits /d/d and so on ..\n",
        "but inorder to simply match all the 10 digits at a time we use /d{10} = excatly 10 of d(0-9)'''"
      ],
      "metadata": {
        "id": "8NShW27jYAgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EKfZdzX4X5iI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat1='hello welcome! whats up ,to contact me msg to 9182017247 or mailto lavanyavaranasi3@gmail.com'\n",
        "chat2=\"hello welcome! whats up ,to contact me msg to 918-201-7247 or mailto lavanyavaranasi3@gmail.com\""
      ],
      "metadata": {
        "id": "BD2ihFkDFD8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matchcheker=re.findall('\\d{10}',chat1)\n",
        "matchcheker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyKCXTSYGazY",
        "outputId": "6f47038c-d6bf-443e-faac-792c3bc33e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['9182017247']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "''' in order to match 091-233-4554 this kind of number we use \" \\(d{3}\\)-\\d{3}-\\d{4} '''"
      ],
      "metadata": {
        "id": "SnbyHYIaYIvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "match2=re.findall('\\d{10}|\\d{3}\\-\\d{3}-\\d{4}',chat2)\n",
        "match2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJR4CgcEKN0J",
        "outputId": "052055de-f4e2-41e6-f60e-f8af69c27bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['918-201-7247']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "f8FpBKCpTPrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** using spacy (oops)**"
      ],
      "metadata": {
        "id": "jApihrlrRfTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(\"Dr. Lavanya ! this is me , and you will. whats up?\")\n",
        "for sentence in doc.sents:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUTO3rxzR1ev",
        "outputId": "821d6ee3-33d9-4faf-8650-eb6f082f8231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr. Lavanya !\n",
            "this is me , and you will.\n",
            "whats up?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in doc.sents:\n",
        "  for words in sentence:\n",
        "    print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Bm3FTZxTIjc",
        "outputId": "8dfc684b-1724-40b0-e47f-0fca6d0f9081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr.\n",
            "lavanya\n",
            "!\n",
            "this\n",
            "is\n",
            "me\n",
            ",\n",
            "and\n",
            "you\n",
            "will\n",
            ".\n",
            "what\n",
            "s\n",
            "up\n",
            "?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*NLTK (string processing)*"
      ],
      "metadata": {
        "id": "OfK7yGXXUElg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJScnd0RUNfL",
        "outputId": "3dbbed33-b5fc-42b9-af1a-5242a0476649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SENTENCE TOKENIZATION**"
      ],
      "metadata": {
        "id": "Qt5InLwrYYZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize( \"Dr. Lavanya ! this is me , and you will. whats up?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjIADPNLUT7G",
        "outputId": "9c888cc1-3435-4324-c4c6-19a3f15c7fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dr. Lavanya !', 'this is me , and you will.', 'whats up?']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NEED TO VERIFY THIS *In spacy if you choose sentence tokenizer and gave input as Dr. then it considers as word itself but if you consider NLTK it takes it as another sentence *"
      ],
      "metadata": {
        "id": "2Cxej83wXCxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WORD TOKENIZER**"
      ],
      "metadata": {
        "id": "cQyXQsLyYk9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(\"Dr. lavanya ! this is me , and you will. whats up?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-KEeO4UXt0f",
        "outputId": "9b2c84d3-f495-4e9d-bb21-0e06c5e27189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello',\n",
              " 'dr.',\n",
              " 'lavanya',\n",
              " '!',\n",
              " 'this',\n",
              " 'is',\n",
              " 'me',\n",
              " ',',\n",
              " 'and',\n",
              " 'you',\n",
              " 'will',\n",
              " '.',\n",
              " 'whats',\n",
              " 'up',\n",
              " '?']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. *: Matches zero or more occurrences.\n",
        "2. +: Matches one or more occurrences.\n",
        "3.  ?: Matches zero or one occurrence.\n",
        "4.  {n}: Matches exactly n occurrences.\n",
        "5.  {n,}: Matches n or more occurrences.\n",
        "6.  {n,m}: Matches at least n and at most m occurrences.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l-z4ugtMBMH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_noise(text):\n",
        "    # Remove noise containing common words\n",
        "    noise_words = ['is', 'a', 'this']\n",
        "    cleaned_text_words = text\n",
        "    for word in noise_words:\n",
        "        pattern = r'\\b{}\\b'.format(word)\n",
        "        cleaned_text_words = re.sub(pattern, '', cleaned_text_words)\n",
        "\n",
        "    # Remove words following hashtags\n",
        "    cleaned_text_hashtags = re.sub(r'#\\w+\\s*', '', text)\n",
        "\n",
        "    # Remove \"@\" symbols\n",
        "    cleaned_text_hashtags = re.sub(r'@\\w+', '', cleaned_text_hashtags)\n",
        "\n",
        "    # Remove extra whitespaces\n",
        "    cleaned_text_hashtags = re.sub(r'\\s+', ' ', cleaned_text_hashtags)\n",
        "\n",
        "    return cleaned_text_words, cleaned_text_hashtags\n",
        "\n",
        "# Example text with noise containing common words and hashtags\n",
        "text = \"This is a #sample text with @some noise!   12345 #removeme #notthisone\"\n",
        "\n",
        "# Remove noise containing common words and hashtags separately\n",
        "cleaned_text_words, cleaned_text_hashtags = remove_noise(text)\n",
        "print(\"Original Text:\")\n",
        "print(text)\n",
        "print(\"\\nCleaned Text (Removing noise containing common words):\")\n",
        "print(cleaned_text_words)\n",
        "print(\"\\nCleaned Text (Removing words following hashtags):\")\n",
        "print(cleaned_text_hashtags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsL-1iRLNv2S",
        "outputId": "1aa562bb-75c8-477a-dcfc-60d096657f0a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "This is a #sample text with @some noise!   12345 #removeme #notthisone\n",
            "\n",
            "Cleaned Text (Removing noise containing common words):\n",
            "This   #sample text with @some noise!   12345 #removeme #notthisone\n",
            "\n",
            "Cleaned Text (Removing words following hashtags):\n",
            "This is a text with noise! 12345 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def noise_removal(text):\n",
        "  noise_words=['is','a','this']\n",
        "  clean_text=text\n",
        "  for word in noise_words:\n",
        "    position=r'\\b{}\\b'.format(word)\n",
        "    clean_text=re.sub(position,'',clean_text)\n",
        "  hashtag_removal=re.sub(r'#\\w+\\s|@\\w+\\s','',text)\n",
        "  return clean_text,hashtag_removal\n",
        "text=\"this code is very #easy @to  do  \"\n",
        "clean_text,hashtag_removal=noise_removal(text)\n",
        "print(text)\n",
        "print(clean_text)\n",
        "print(hashtag_removal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jODJ109pYEfu",
        "outputId": "d80fc0a6-8dd3-4015-dd15-9ba1bede2233"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this code is very #easy @to  do  \n",
            " code  very #easy @to  do  \n",
            "this code is very  do  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def noise_removal(text):\n",
        "  for word in text:\n",
        "        pattern = r'\\b{}\\b'.format(word)\n",
        "  hashremoval=re.sub(r'@\\w+|#\\w+\\s|\\s',' ',text)\n",
        "  return hashremoval\n",
        "text=\"this code is very #easy is @it \"\n",
        "print(noise_removal(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBJYrBHCcuj9",
        "outputId": "b72a268e-90ad-4f93-c6cf-6f9b5123b6d3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this code is very  is   \n"
          ]
        }
      ]
    }
  ]
}